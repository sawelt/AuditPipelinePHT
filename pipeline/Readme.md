## Security Audit Pipeline
Here we provide code for the different steps of the security audit pipeline. For some steps we use tools provided by [Gitlab](https://about.gitlab.com).
The subfolders of this directory contain the source code for Docker images that are part of the security audit pipeline. Below you can find an overview of the different steps and a description for each step.

Name | Description | YAML Job Name | Link
--- | --- | --- | ---
SAST | Utilizing the built-in gitlab tools for _Static Application Security Testing_ (SAST) we detect a broad range of known vulnerabilities | semgrep-sast | [Link to Documentation](https://docs.gitlab.com/ee/user/application_security/sast/)
Secret Detection | We use the secret detection tools provided by gitlab to check for any accidental leaks of secrets, e.g. private keys for authentication at a station | secret_detection | [Link to Documentation](https://docs.gitlab.com/ee/user/application_security/secret_detection/pipeline/index.html)
Dependency Scanning | The dependency scanning toolset provided by Gitlab scans the (potentially transitive) dependencies of a project for known vulnerabilities | gemnasium-python-dependency_scanning | [Link to Documentation](https://docs.gitlab.com/ee/user/application_security/dependency_scanning/)
Disallowlist | The Disallowlist specifies ceratin regex patterns that are not allowed to be contained in the train's code | disallowlist_check | [Link to files](disallow_list_check)
Compliance Checker | Formats the file and tests whether or not the _padme-conductor_ module is used in the python scripts | inspect_image | [Link to files](compliance_checker)
Image Analysis | Using _Snyk_ we can scan the container image for vulnerabilities | inspect_image | [Link to Documentation](https://docs.snyk.io/getting-started)
DAST | With the _Dynamic Application Security Testing_ (DAST) step we simulate the train in a controlled environment scanning for vulnerabilities at runtime, e.g. communication with a third party server | simulation_train | [Link to files](https://github.com/PADME-PHT/playground/)
Decision Maker | In the last part we make a decision on whether to reject or accept the train based on the results generated by the previous pipeline steps | decision | [Link to files](decision)

## Using Gitlab CI with YAML
```
.build_base_rule:
  rules:
    - if: \$BUILD_ALL == "true"
    - exists: [$trainDir/Dockerfile]
      changes: [$trainDir/**/*]

.build_simulation_rule:
  rules:
    - exists:
      - $trainDir/route.json


.build-tex:
  artifacts:
    paths:
      - ./main.pdf
      - ./job.env
  script:
    - generatePDF.sh
  after_script:
    - echo "JOB_ID=$CI_JOB_ID" >> job.env

sanity_check:
  stage: sanity-check
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/trainsanitychecker/image:main
  rules:
    - !reference [.build_base_rule, rules]
  script:
    - echo "Perform Sanity Check"
    - sanitycheck.sh $trainDir
    - echo "Sanity Check done."

pdf_annotations:
  stage: test
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/abstractsyntaxtreescript/image:main
  before_script:
  - python3 -V
  rules:
    - !reference [.build_base_rule, rules]
  script:
    - echo "Creating Annoation"
    - createCodeAnnotations.sh $trainDir
    - echo "Creating Annoation done."
  artifacts:
    paths: 
    - pdf_annotations.json
    
semgrep-sast:
  extends: .sast-analyzer
  artifacts:
    paths: [gl-sast-report.json]
    reports:
      sast: gl-sast-report.json
  rules:
    - !reference [.build_base_rule, rules]
  image:
    name: "\$SAST_ANALYZER_IMAGE"
  variables:
    SAST_EXCLUDED_PATHS: ${ignorelist:1}
    SEARCH_MAX_DEPTH: 20
    SAST_ANALYZER_IMAGE_TAG: 3
    SAST_ANALYZER_IMAGE: "\$SECURE_ANALYZERS_PREFIX/semgrep:\$SAST_ANALYZER_IMAGE_TAG\$SAST_IMAGE_SUFFIX"
  after_script:
    - cat gl-sast-report.json
    - cat gl-sast-report.json > test1.log


secret_detection:
  extends: .secret-analyzer
  artifacts:
    paths: [gl-secret-detection-report.json]
    reports:
      secret_detection: gl-secret-detection-report.json
  rules:
    - !reference [.build_base_rule, rules]
  variables:
    SECRET_DETECTION_EXCLUDED_PATHS: ${ignorelist:1}
  script:
    - /analyzer run
  after_script:
    - cat gl-secret-detection-report.json
    - cat gl-secret-detection-report.json > test2.log

gemnasium-python-dependency_scanning:
  before_script:
    - apt-get update
    - apt-get install -y libpq-dev
  extends:
    - .ds-analyzer
    - .cyclonedx-reports
  artifacts:
    paths: [gl-dependency-scanning-report.json]
    reports:
      dependency_scanning: gl-dependency-scanning-report.json  
  variables:
    DS_ANALYZER_NAME: "gemnasium-python"
    DS_EXCLUDED_PATHS: ${ignorelist:1}
  rules:
    - !reference [.build_base_rule, rules]
  after_script:
    - cat gl-dependency-scanning-report.json
    - cat gl-dependency-scanning-report.json > test4.log

inspect_static:
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/inspectstaticimage/image:main
  stage: test
  rules:
    - !reference [.build_base_rule, rules]
  before_script:
    - apk update && apk add --no-cache jq && apk add --no-cache bash && apk add --no-cache git
  script:
    - inspect_static.sh
    # dump the $CI_JOB_ID to a file
    - echo \$CI_JOB_ID > static_job_id.txt
  needs:
    - gemnasium-python-dependency_scanning
    - secret_detection
    - semgrep-sast
    - disallowlist_check
  artifacts:
    paths:
      - static_report.json
      - static_job_id.txt

check_compliance:
  stage: test
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/compliancechecker/image:main
  rules:
    - !reference [.build_base_rule, rules]
  script:
    - pip install -r $trainDir/requirements.txt
    - compliance_check.sh $trainDir
    - echo \$CI_JOB_ID > compliance_job_id.txt
  artifacts:
    paths:
      - compliance_report.json
      - compliance_job_id.txt

inspect_image:
  stage: test
  rules:
    - !reference [.build_base_rule, rules]
  image: docker:latest
  artifacts:
    paths:
      - image_report.json
      - inspect_image_job_id.txt
      - image_inspect.json
  before_script:
    - apk update && apk add --no-cache nodejs && apk add --no-cache npm
    - npm install snyk -g
  script:
    - docker build -t train_image $trainDir/
    - snyk auth \$SNYK_TOKEN
    - snyk container test train_image --prune-repeated-subdependencies --max-old-space-size=8192 --file=$trainDir/Dockerfile --json > image_report.json || true
    - docker inspect train_image > image_inspect.json
    - echo \$CI_JOB_ID > inspect_image_job_id.txt
  retry: # this job can fail indeterministically
    max: 2

disallowlist_check:
  stage: test
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/disallowlistimage/image:main
  before_script:
    - apk update && apk add --no-cache bash && apk add --no-cache jq
  script:
    - disallowlist_check.sh $trainDir
  artifacts:
    paths:
      - regex_matches.json
  rules:
    - !reference [.build_base_rule, rules]

simulation_train:
  stage: test
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/trainsimulator/image:main
  rules:
    - !reference [.build_simulation_rule, rules]
  before_script:
    - apk update && apk add --no-cache bash
  script:
    - setup_env.sh
    - ls
    - echo "Simulating..."
    - if [[ "$gpuenabled" == "true" ]]; then
        simulatetrain.sh $trainDir --gpu-enabled;
      else
        simulatetrain.sh $trainDir;
      fi
    - echo "Simulation complete."
    - ls
    - echo \$CI_JOB_ID > dynamic_job_id.txt
  artifacts:
    paths:
      - dynamic_report.json
      - dynamic_job_id.txt
      - ./simulationResults/

decision:
  stage: decision
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/decisionmaker/image:main
  rules:
    - !reference [.build_base_rule, rules]
  before_script:
    - apk update && apk add --no-cache bash
    - echo "Importing Decision Model from $DECISION_MODEL_PATH"
    - mv $DECISION_MODEL_PATH decision_model.json
    - cat decision_model.json
  script:
    - decision.sh
    - echo \$CI_JOB_ID > decision_job_id.txt
  artifacts:
    paths:
      - decision.json   
      - decision_job_id.txt

build_tex_sources:
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/texsourcesbuilder/image:main
  stage: reporting
  before_script:
    - apk update && apk add --no-cache bash
  script:
    - echo "Build tex..."
    - generateTex.sh $trainDir
    - echo "Built complete."
  artifacts:
    paths:
      - codebase.tex
      - conclusion.tex
      - connectionParameters.tex
      - dast.tex
      - imageast.tex
      - imagebuildingfile.tex
      - inputStrings.sty
      - requirementsdependencies.tex
      - sast.tex

build_audit_pdf:
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/auditreporttemplate/image:main
  stage: finalize-report
  extends: .build-tex

build:
  stage: build
  image: docker:20
  rules:
    - !reference [.build_base_rule, rules]
  before_script:
    - echo \$CI_JOB_TOKEN | docker login -u \$CI_REGISTRY_USER --password-stdin \$CI_REGISTRY
  script: 
    - docker pull $CI_REGISTRY_IMAGE/$tag:latest || true
    - > 
      docker build 
      --pull
      --cache-from $CI_REGISTRY_IMAGE/$tag:latest 
      --tag $CI_REGISTRY_IMAGE/$tag:latest $trainDir/.

push_to_gitlab:
  stage: push-to-gitlab
  image: docker:20
  rules:
    - !reference [.build_base_rule, rules]
  variables:
    GIT_STRATEGY: none
  needs: 
    - job: build
  before_script:
    - echo \$CI_JOB_TOKEN | docker login -u \$CI_REGISTRY_USER --password-stdin \$CI_REGISTRY
  script:
    - docker push $CI_REGISTRY_IMAGE/$tag:latest

push_to_harbor:
  stage: push-to-harbor
  image: docker:20
  rules:
    - !reference [.build_base_rule, rules]
  variables:
    GIT_STRATEGY: none
  needs: 
    - job: build
  before_script:
    - echo \$HARBOR_REGISTRY_PASSWORD | docker login -u \$HARBOR_REGISTRY_USER --password-stdin \$HARBOR_REGISTRY
  script:
    - docker tag $CI_REGISTRY_IMAGE/$tag $HARBOR_REGISTRY/train_class_repository/$tag
    - docker push $HARBOR_REGISTRY/train_class_repository/$tag

ast:
  stage: build
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/abstractsyntaxtreescript/image:main
  before_script:
  - python3 -V
  rules:
    - !reference [.build_base_rule, rules]
  script:
    - echo "Creating AST"
    - createASTTreeForTrain.sh $trainDir
    - echo "Creating AST done."

archive_artifacts:
  stage: build
  image: $CI_REGISTRY/$CI_PROJECT_NAMESPACE/miniouploader/image:main
  before_script:
    - mkdir -p artefacts
    - mv main.pdf artefacts/
    - mv decision.json artefacts/
    - ls
  script:
    - echo "Upload Artefacts"
    - uploadArtefacts.sh $trainDir
    - echo "Upload complete."
  rules:
    - !reference [.build_base_rule, rules]
```